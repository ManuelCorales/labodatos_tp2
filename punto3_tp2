#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Mar  2 15:15:41 2024

@author: NAtali Biasoni
"""


from sklearn.tree import DecisionTreeClassifier,plot_tree, export_graphviz
import graphviz
import pandas as pd
from inline_sql import sql, sql_val
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, RandomizedSearchCV,  KFold, cross_val_score, cross_val_score
#%%
carpeta= "/home/oem/Desktop/uni/labodatos/"
señas_df= pd.read_csv(carpeta+"sign_mnist_train.csv")

#%%
#CREO UN DATASET SOLO DE VOCALES#
#HAy 1126 datos para la letra a
#hay 957 datos para la letra e
#hay 1162 datos para la letra i
#hay 1196 datos para la letra o
#hay 1161 datos para la letra u

df_vocales= sql^"""
     Select * 
     FROM señas_df
     WHERE label = 0 OR label =4 OR label = 8
      OR label =14 OR label = 20
     """
print(df_vocales.head())     
#%%
#Separo los datos para el entrenamiento y el test 
X= df_vocales.drop(columns = ['label'])
Y= df_vocales['label']
X_train, X_test, y_train, y_test =  train_test_split(X, Y, test_size=0.15 , shuffle=True, stratify=  Y)
#%%
#busco el mejor arbol
hyper_params = {'criterion' : ["gini", "entropy"],
                   'max_depth' : [2,3,4,5,6] }

arbol = DecisionTreeClassifier()
clf = RandomizedSearchCV(arbol, hyper_params, random_state= 0, n_iter= 5)
clf.fit(X_train, y_train)
clf.best_params_
clf.best_score_
#lo hago a mano por las dudas
def busco_mejor_arbol (c:list, md:list):
    best_score= 0
    for criterio in c:
        for depth in md:
            arbol = DecisionTreeClassifier(criterion = criterio, max_depth=depth)
            scores = cross_val_score(arbol, X_train, y_train, cv=5)
            prom_score= np.mean(scores)
            if prom_score > best_score:
                best_score= prom_score
                hyperparams:list = []
                hyperparams.append(criterio)
                hyperparams.append(depth)
    return best_score, hyperparams  
print(busco_mejor_arbol( ["gini", "entropy"], [2,3,4,5,6] ))  
#%%
#el mejor arbol tienen los hyperparametros max depth = 6 y criterio = entropy
#lo evaluo con los datos test
clf.score(X_test, y_test)


